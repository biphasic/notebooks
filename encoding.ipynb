{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "If we want to do computation with spiking neurons, the first question to ask ourselves is how to encode data (images, video, audio, text, etc.) into spikes. We can approach this problem from either a purely practical perspective or be guided by what is known from biological nervous systems. Biological nervous systems also process additional sensory modalities which aren't typically considered in the machine learning literature, such as smell, touch, etc.\n",
    "\n",
    "In Norse we operate primarily on tensors of data, irrespective of the origin of this data. For\n",
    "example an image naturally is encoded as a tensor with shape (C, W, H), where C is the number\n",
    "channels (colors), W is the width and H is the height of the image. \n",
    "\n",
    "In this notebook you will explore\n",
    "- an overview of some of the encoders build into Norse\n",
    "- project ideas related to encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Installation\n",
    "\n",
    "First of all, we will need to install Norse. Please run the cell below. Read on while it's running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet norse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an implementation of two helpful functions to visualise 2d spike trains\n",
    "as they are produced by norse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import norse\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_activity_2d(fig, z : torch.Tensor):\n",
    "    channels = z.shape[2]\n",
    "    B = z.shape[1]\n",
    "    T = z.shape[0]\n",
    "    for c in range(channels):\n",
    "        ax = fig.add_subplot(1, channels, c+1)\n",
    "        s = ((z[:,:,c].sum(axis=0)/T).sum(axis=0)/B)\n",
    "        ax.matshow(s)\n",
    "\n",
    "def plot_spikes_2d(fig, z):\n",
    "    T = z.shape[0]\n",
    "    C = z.shape[1]\n",
    "\n",
    "    for c in range(C):\n",
    "        ax = fig.add_subplot(1, C, c+1, projection='3d')\n",
    "        s = z[:,c].detach().to_sparse().coalesce()\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        ax.invert_zaxis()\n",
    "        ax.set_xlim([0,T])\n",
    "        ax.set_xlabel('time [ms]')\n",
    "        ax.scatter(s.indices()[0], s.indices()[2], s.indices()[1], s=1.0, c=s.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Built in Encoders\n",
    "\n",
    "In order to convert non-spiking data to spikes one convenient way\n",
    "are to use an encoding as a Poisson spike train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = norse.functional.encode.poisson_encode(1.4 * torch.ones(1, 32, 32), seq_length=48)\n",
    "fig = plt.figure()\n",
    "plot_spikes_2d(fig, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another is to treat the data as a constant input current to a LIF \n",
    "neuron. In this case the latency between consecutive spikes,  aswell as the overall firing frequency, carries the information \n",
    "about the encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 48\n",
    "v_th = 1.0\n",
    "\n",
    "z = norse.functional.encode.constant_current_lif_encode(\n",
    "    1.4 * torch.ones(1, 32, 32), \n",
    "    p=norse.torch.functional.lif.LIFParameters(v_th=torch.as_tensor(v_th)),\n",
    "    seq_length=T\n",
    ")\n",
    "fig = plt.figure()\n",
    "plot_spikes_2d(fig, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "- Change the threshhold voltage (v_th), what happens? Why?\n",
    "- Change other neuron parameters (hint they can be found by executing the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norse.torch.functional.lif.LIFParameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss: \n",
    "- What other encoders might be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Image Data\n",
    "\n",
    "We can test out these encoders on \"real\" data: Namely the beloved MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "- Try out a different dataset an overview can be found [here](https://pytorch.org/docs/stable/torchvision/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0]\n",
    "\n",
    "T = 32\n",
    "z = norse.torch.functional.encode.constant_current_lif_encode(img, seq_length=T)\n",
    "\n",
    "fig = plt.figure()\n",
    "plot_spikes_2d(fig, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plot_activity_2d(fig, z.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Project Ideas\n",
    "\n",
    "- Find out about Adress Event encoded data, such as the one produced by DVS cameras and\n",
    "think of an interesting task to implement. We have implemented\n",
    "a library which will allow you to directly import adress event encoded data into Norse:\n",
    "[aedat](https://github.com/norse/aedat)\n",
    "- Design a task which uses a biologically plausible Audio to Spike conversion like\n",
    "  [lauscher](https://github.com/electronicvisions/lauscher).\n",
    "- What other data could be used as input to a Spiking Neural Network and how?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
